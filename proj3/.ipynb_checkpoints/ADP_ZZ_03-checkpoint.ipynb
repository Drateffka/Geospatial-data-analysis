{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53dfee5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4d572b9cb35f7417343f3db3cd5a898",
     "grade": false,
     "grade_id": "cell-fcd2666579131b77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Analiza danych przestrzennych - ćwiczenia laboratoryjne 2022/2023\n",
    "\n",
    "Ten notatnik zalicza się do grupy zestawów zadań, na podstawie których odbywa się zaliczenie ćwiczeń i podlega zwrotowi do oceny w ustalonym na zajęciach terminie.\n",
    "\n",
    "Uwagi ogólne:\n",
    "- Podczas wykonywania zadań należy korzystać wyłącznie z pakietów zaimportowanych na początku notatnika oraz z pakietów wchodzących w skład standardowej biblioteki Pythona, które można zaimportować samodzielnie we wskazanej komórce.\n",
    "- Swoje rozwiązania należy wprowadzać wyłącznie w miejce następujących fragmentów kodu:<br/> ` # YOUR CODE HERE`<br/> ` raise NotImplementedError()`<br/> Nie należy w żaden sposób modyfikować pozostałych fragmentów kodu oraz elementów notatnika, w szczególności dodawać lub usuwać komórek oraz zmieniać nazwy pliku.\n",
    "- Jeżeli zestaw zadań wymaga skorzystania z funkcji przygotowanych w ramach wcześniejszych zestawów zadań należy je umieścić we wskazanej komórce.\n",
    "- Wszystkie wykresy powinny być wykonane w jednolitym, przejrzystym i czytelnym stylu, mieć nadane tytuły, opisane osie oraz odpowiednio dobrany rozmiar, wielkość punktów i grubość linii. Proporcje osi wykresów przedstawiających rozkłady punktów powinny być dobrane tak, aby wykresy odzwierciedlały rzeczywisty rozkład punktów w przestrzeni.\n",
    "- Zadania, które powodują wyświetlenie komunikatu o błędzie przerywającym wykonywanie kodu nie podlegają ocenie.\n",
    "\n",
    "Przed odesłaniem zestawu zadań do oceny proszę uzupełnić komórkę z danymi autorów rozwiązania (`NAME` - nazwa grupy, `COLLABORATORS` - imiona, nazwiska i numery indeksów członków grupy) oraz upewnić się, że notatnik działa zgodnie z oczekiwaniami. W tym celu należy skorzystać z opcji **Restart Kernel and Run All Cells...** dostępnej na górnej belce notatnika pod symbolem $\\blacktriangleright\\blacktriangleright$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62315a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"IAD15\"\n",
    "COLLABORATORS = \"Anna Kaniowska 407334, Weronika Matuszek 406887, Ewa Szewczyk 406923, Adam Piwowarski 408133\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f5797",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eddc8826810e4a6f7bf68319da334bd9",
     "grade": false,
     "grade_id": "cell-109006d425e5cf83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28276681-0950-4312-92cb-792a97f88e2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b043234b4053b1ed7c51d086e070d9f",
     "grade": false,
     "grade_id": "cell-1f33a09e5146ecbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Zestaw zadań 3: Badanie intensywności procesów punktowych (część 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560aae70-e3b4-4a1a-961f-54eebe9922ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31642740d59cb98672cfd1ca55108013",
     "grade": false,
     "grade_id": "cell-ecd0d56207650fc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85336381-f0de-4bb0-bbd0-d0849707ed38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Miejsce do importu pakietów wchodzących w skład standardowej biblioteki Pythona oraz ustawienie opcji wykorzystywanych pakietów\n",
    "sns.set() \n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ece9eb9-c0d1-479e-bbc2-eddadcef70b5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a483085d48433d55febe96f376d34572",
     "grade": true,
     "grade_id": "cell-885489b562915779",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Miejsce do wklejenie funkcji ze wcześniejszych zestawów zadań\n",
    "# YOUR CODE HERE\n",
    "\n",
    "def regular_on_rectangle(grid, random_component, x_lim, y_lim):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    grid: list\n",
    "        Lista określająca liczbę punktów w pionie i poziomie.\n",
    "        Przykład: [10, 10]\n",
    "    random_component: float\n",
    "        Liczba z przedziału [0, 1] określająca wielkość komponentu losowego.\n",
    "    x_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej X.\n",
    "        Przykład: [0, 10]\n",
    "    y_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej Y.\n",
    "        Przykład: [0, 10]   \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    points: DataFrame\n",
    "        Tablica zawierająca dwie kolumny ze współrzędnymi punktów opisane jako \"X\" i \"Y\".\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Creating variables containing distance between points\n",
    "    dx = (x_lim[1] - x_lim[0])/grid[0]\n",
    "    dy = (y_lim[1] - y_lim[0])/grid[1]\n",
    "\n",
    "    # Creating gird with regular gaps (without random component)\n",
    "    x = np.arange(x_lim[0] + 0.5*dx, x_lim[1], dx)\n",
    "    y = np.arange(y_lim[0] + 0.5*dy, y_lim[1], dy)\n",
    "    xy, yx = np.meshgrid(x, y)\n",
    "    \n",
    "    # Adding random component to our gird\n",
    "    rand_m1 = [[random_component*np.random.uniform(-0.5*dx, 0.5*dx) for i in range(grid[0])] for j in range(grid[1])]\n",
    "    rand_m2 = [[random_component*np.random.uniform(-0.5*dy, 0.5*dy) for i in range(grid[0])] for j in range(grid[1])]\n",
    "    mx = xy + rand_m1\n",
    "    my = yx + rand_m1\n",
    "\n",
    "    # Flattening previously created matrices and creating required DataFrame\n",
    "    xx = mx.flatten()\n",
    "    yy = my.flatten()\n",
    "    points = pd.DataFrame([xx, yy]).transpose()\n",
    "    points.columns=[\"X\", \"Y\"]\n",
    "    return points\n",
    "\n",
    "\n",
    "def homogeneous_poisson_on_rectangle(intensity, x_lim, y_lim):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    intensity: float\n",
    "        Liczba dodatnia określająca intensywność procesu punktowego.\n",
    "    x_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej X.\n",
    "        Przykład: [0, 10]\n",
    "    y_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej Y.\n",
    "        Przykład: [0, 10]   \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    points: DataFrame\n",
    "        Tablica zawierająca dwie kolumny ze współrzędnymi punktów opisane jako \"X\" i \"Y\".\n",
    "    \"\"\" \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #drawing number of points from Poisson distribution\n",
    "    area = (x_lim[1]-x_lim[0])*(y_lim[1]-y_lim[0]);\n",
    "    w = intensity * area\n",
    "    n = np.random.poisson(w)\n",
    "    \n",
    "    #drawing coordinates of points from uniform distribution\n",
    "    x_tab = np.random.uniform(x_lim[0],x_lim[1],n)\n",
    "    y_tab = np.random.uniform(y_lim[0],y_lim[1],n)\n",
    "    \n",
    "    #creating DataFrame\n",
    "    points = pd.DataFrame({'X':x_tab,'Y':y_tab})\n",
    "    return points\n",
    "    \n",
    "def unhomogeneous_poisson_on_rectangle(intensity_function, x_lim, y_lim):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    intensity_function: function\n",
    "        Funkcja przyjmująca dwa argumenty (macierz 1D współrzędnych X i macierz 1D współrzędnych Y) i zwracająca macierz 1D\n",
    "        z wartościami funkcji opisującej intensywność procesu dla tych współrzędnych.\n",
    "    x_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej X.\n",
    "        Przykład: [0, 10]\n",
    "    y_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej Y.\n",
    "        Przykład: [0, 10] \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    points: DataFrame\n",
    "        Tablica zawierająca dwie kolumny ze współrzędnymi punktów opisane jako \"X\" i \"Y\".\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    #redefining intensity function for sp.optimize.minimize purpose\n",
    "    def intensity_function_2(params):\n",
    "        if(len(params)!=2):\n",
    "            print(\"Error in intensity_function_2: intensity_function takes 2 arguments\")\n",
    "            return \n",
    "        \n",
    "        return -intensity_function(params[0],params[1])\n",
    "    \n",
    "    #optimizing intensity function & setting i_max value\n",
    "    optimize_result = sp.optimize.minimize(intensity_function_2, \n",
    "                                           [sum(x_lim)/2,sum(y_lim)/2], \n",
    "                                           method='Nelder-Mead', \n",
    "                                           bounds=(tuple(x_lim),tuple(y_lim))) \n",
    "    i_max = -optimize_result.fun\n",
    "\n",
    "    #simulating homogenous poisson point process\n",
    "    points = homogeneous_poisson_on_rectangle(i_max, x_lim, y_lim)\n",
    "    num_points = len(points['X'])\n",
    "\n",
    "    #counting probabilities for each point\n",
    "    p = (1-(-intensity_function_2((points['X'],points['Y'])))/i_max).to_frame()\n",
    "    p.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    #deciding which points to delete & deleting them\n",
    "    delete = np.random.uniform(0,1,((num_points,1)))<p;\n",
    "    points.drop(delete[delete['X']==True].index,inplace=True)\n",
    "\n",
    "    return points\n",
    "\n",
    "def materna_on_rectangle(parent_intensity, daughter_intensity, cluster_radius, x_lim, y_lim):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    parent_intensity: float\n",
    "        Liczba dodatnia określająca intensywność macierzystego procesu punktowego.\n",
    "    daughter_intensity: float\n",
    "        Liczba dodatnia określająca intensywność potomnego procesu punktowego.\n",
    "    cluster_radius: float\n",
    "        Liczba dodatnia określająca promień generowanych klastrów.\n",
    "    x_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej X.\n",
    "        Przykład: [0, 10]\n",
    "    y_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej Y.\n",
    "        Przykład: [0, 10]   \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    points: DataFrame\n",
    "        Tablica zawierająca dwie kolumny ze współrzędnymi punktów opisane jako \"X\" i \"Y\".\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Extending our area with a buffer\n",
    "    x_new = [x_lim[0] - cluster_radius, x_lim[1] + cluster_radius]\n",
    "    y_new = [y_lim[0] - cluster_radius, y_lim[1] + cluster_radius]\n",
    "\n",
    "    # Generating point by homogeneous Poisson process with parent_intensity as a parameter\n",
    "    points = homogeneous_poisson_on_rectangle(parent_intensity, x_new, y_new)\n",
    "   \n",
    "   # Generating new points around each previous points (within cluster_radius)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for i in range(len(points['X'])):\n",
    "      # Triggering nex\n",
    "      number = np.random.poisson(daughter_intensity*np.pi*cluster_radius**2);\n",
    "      # Generating the (relative) locations in polar coordinates by simulating independent variables\n",
    "      theta=2*np.pi*np.random.uniform(0,1,number); \n",
    "      rho=cluster_radius*np.sqrt(np.random.uniform(0,1,number)); \n",
    "      # Converting from polar to Cartesian coordinates\n",
    "      dx = rho * np.cos(theta);\n",
    "      dy = rho * np.sin(theta);\n",
    "      # Translating points (by treating old points as a center of our buffer)\n",
    "      for j in range(number):\n",
    "        valueX=points.iloc[i, 0]+dx[j]\n",
    "        valueY=points.iloc[i, 1]+dy[j]\n",
    "        X.append(valueX)\n",
    "        Y.append(valueY)\n",
    "    \n",
    "    # Creating DatFrame\n",
    "    clustered=pd.DataFrame({\"X\": X, \"Y\":Y})\n",
    "\n",
    "    # Checking if some new point aren't within our area and if so - adding their indexes to a list\n",
    "    indexes=[]\n",
    "    for i, row in clustered.iterrows():\n",
    "      if(row[\"X\"] < x_lim[0] or row[\"X\"] > x_lim[1] or row[\"Y\"] < y_lim[0] or row[\"Y\"] > y_lim[1]):\n",
    "        indexes.append(i)\n",
    "\n",
    "    # Dropping points that are outside of the area\n",
    "    clustered.drop(clustered.index[indexes], inplace=True)\n",
    "    clustered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return clustered\n",
    "    \n",
    "def thomas_on_rectangle(parent_intensity, mean_cluster_size, cluster_sigma, x_lim, y_lim):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    parent_intensity: float\n",
    "        Liczba dodatnia określająca intensywność macierzystego procesu punktowego.\n",
    "    mean_cluster_size: float\n",
    "        Liczba dodatnia określająca oczekiwaną liczebność generowanych klastrów.\n",
    "    cluster_sigma: float\n",
    "        Liczba dodatnia określająca odchylenie standardowe rozkładu wykorzystywanego w procesie generowania klastrów.\n",
    "    x_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej X.\n",
    "        Przykład: [0, 10]\n",
    "    y_lim: list\n",
    "        Lista określająca zakres wartości współrzędnej Y.\n",
    "        Przykład: [0, 10]   \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    points: DataFrame\n",
    "        Tablica zawierająca dwie kolumny ze współrzędnymi punktów opisane jako \"X\" i \"Y\".\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #setting extended limits, drawing points from homogeneous Poisson point process\n",
    "    x_new = [x_lim[0] - 4*cluster_sigma, x_lim[1] + 4*cluster_sigma]\n",
    "    y_new = [y_lim[0] - 4*cluster_sigma, y_lim[1] + 4*cluster_sigma]\n",
    "    centers = homogeneous_poisson_on_rectangle(parent_intensity, x_new, y_new)\n",
    "    \n",
    "    #adding points to clusters\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for c in centers.values:\n",
    "      n = np.random.poisson(mean_cluster_size)\n",
    "      for i in range(n):\n",
    "        x = np.random.normal(c[0], cluster_sigma)\n",
    "        y = np.random.normal(c[1], cluster_sigma)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "    clustered=pd.DataFrame({\"X\" : X, \"Y\" : Y})\n",
    "\n",
    "    #droping points outside targeted area\n",
    "    indexes=[]\n",
    "    for i, row in clustered.iterrows():\n",
    "      if(row[\"X\"] <x_lim[0] or row[\"X\"] > x_lim[1] or row[\"Y\"] < y_lim[0] or row[\"Y\"] > y_lim[1]):\n",
    "        indexes.append(i)\n",
    "\n",
    "    clustered.drop(clustered.index[indexes], inplace=True)\n",
    "    clustered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return clustered\n",
    "\n",
    "def point_count_on_subregions(points, bins, x_lim, y_lim):\n",
    "    n_points,x_bins,y_bins = np.histogram2d(points['X'],points['Y'],bins=bins,range=[x_lim,y_lim])     \n",
    "    n_points = np.transpose(n_points)\n",
    "    return n_points\n",
    "\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd1f64-87d1-4158-acc2-bc3c5929a5bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a36d83b72601f5d199de8f7f6f9c22f",
     "grade": false,
     "grade_id": "cell-f2afbf273f0dc494",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Przygotowanie danych\n",
    "Wczytaj dane zawarte w plikach CSV załączonych do zestawu zadań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdc9df9-80a1-45fe-a3e0-bcc9a3268595",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca678f358d65294068eb38894d14931",
     "grade": true,
     "grade_id": "cell-ade1720260927626",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "points_1 = pd.read_csv(\"points_1.csv\")\n",
    "points_2 = pd.read_csv(\"points_2.csv\")\n",
    "points_3 = pd.read_csv(\"points_3.csv\")\n",
    "n1 = point_count_on_subregions(points_1, [40,20], [0,20], [0,10])\n",
    "n2 = point_count_on_subregions(points_2, [40,20], [0,20], [0,10])\n",
    "n3 = point_count_on_subregions(points_3, [40,20], [0,20], [0,10])\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a75976-cb9d-4da6-b501-73a9f60bfb6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "743eda14608e95a5584ec64d8ebe593a",
     "grade": false,
     "grade_id": "cell-cf8e2b1190d2c9a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Zadanie 1: Test chi-kwadrat Pearsona (30 pkt)\n",
    "\n",
    "Przygotuj funkcję `pearsons_chi2_test()`, która będzie przeprowadzać test istotności chi-kwadrat Pearsona i wyświetlać jego wynik zgodnie z pokazanym poniżej schematem. Następnie wykorzystaj przygotowanią funkcję do sprawdzenia, czy rozkłady punktowe zaimportowane z plików points_1.csv i points_2.csv są jednorodnymi rozkładami Poissona o intensywności równej 20. W obliczeniach przyjmij $\\alpha=0.05$.\n",
    "\n",
    "Rozwiązanie zadania wymaga dodatkowo przygotowania funkcji pomocniczych `distribution_table()` i `poisson_distribution_table()`, które będą przygotowywać szeregi rodzielcze testowanego rozkładu oraz teoretycznego rozkładu Poissona.\n",
    "\n",
    "Algorytm postępowania:\n",
    "- Formułujemy hipotezę zerową i hipotezę alternatywną H1: <br/>\n",
    "H0: Testowana zmienna ma przyjęty rozkład teoretyczny <br/>\n",
    "H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\n",
    "- Obliczamy wartość statystyki testowej $\\chi^2$: <br/>\n",
    "$\\chi^2 = \\sum_{i=1}^{k} \\frac{(n_i-n p_i)^2}{np_i}$ <br/>\n",
    "gdzie: $k$ - liczba wariantów badanej cechy, $n_i$ - liczebność i-tego wariantu testowanego rozkładu, $n$ - liczba punktów testowanego rozkładu, $p_i$ - prawdopodobieństwo  i-tego wariantu rozkładu teoretycznego.\n",
    "- Z rozkładu chi-kwadrat wyznaczamy obszar krytyczny testu istotności $\\chi^2_{\\alpha}$: <br/>\n",
    "$\\chi^2_{\\alpha} = \\chi^2_{1-\\alpha, k-s-1}$ <br/>\n",
    "gdzie:  $\\alpha$ - poziom istotności, $k$ - liczba wariantów rozkładu, $s$ - liczba nieznanych parametrów rozkładu.\n",
    "- Podejmujemy decyzję weryfikującą: <br/>\n",
    "$\\chi^2 >= \\chi^2_{\\alpha}$ - Odrzucenie H0 na rzecz H1 na poziomie istotności alpha = X <br/>\n",
    "$\\chi^2 < \\chi^2_{\\alpha}$ - Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha = X\n",
    "\n",
    "Przykładowe wyniki pracy funkcji `pearsons_chi2_test()`: <br/>\n",
    "<br/>\n",
    "`Test chi-kwadrat Pearsona` <br/>\n",
    "`H0: Testowana zmienna ma przyjęty rozkład teoretyczny` <br/>\n",
    "`H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego` <br/>\n",
    "`chi2 = 23.307 chi2_alpha = 18.078`<br/>\n",
    "`chi2 >= chi2_alpha` <br/>\n",
    "`Odrzucenie H0 na rzecz H1 na poziomie istotności alpha = 0.05` <br/>\n",
    "<br/>\n",
    "`Test chi-kwadrat Pearsona` <br/>\n",
    "`H0: Testowana zmienna ma przyjęty rozkład teoretyczny` <br/>\n",
    "`H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego` <br/>\n",
    "`chi2 = 19.521 chi2_alpha = 21.129`<br/>\n",
    "`chi2 < chi2_alpha` <br/>\n",
    "`Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha = 0.05` <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e76302-a74f-4232-a713-e522e1553861",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2af9f2874b81554258b2ac57538e46c9",
     "grade": false,
     "grade_id": "cell-3bd38731291da2b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### a) Przygotowanie funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf751bf0-f36a-4377-b6cc-a259336a5b4a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "015dda85cd36cde13e47973e3dac329e",
     "grade": true,
     "grade_id": "cell-357a2ee8390da86b",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distribution_table(bin_counts):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    bin_counts: array\n",
    "        Macierz 2D z liczbą punków przypisanych do każdego z podobszarów.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    table: DataFrame\n",
    "        Tablica zawierająca 2 kolumny:\n",
    "        - \"K\", która zawiera wszystkie wartości całkowite z zakresu od minimalnej do maksymalnej liczby zliczeń w obrębie podobszarów,\n",
    "        - \"N(K)\", która zawiera liczby podobszarów, którym zostały przypisane poszczególne liczby punktów.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # calculating min and max of counts\n",
    "    kmax = np.max(bin_counts)\n",
    "    kmin = np.min(bin_counts)\n",
    "\n",
    "    # creating result columns\n",
    "    K = np.arange(kmin, kmax + 1)\n",
    "    NK = np.bincount(np.ndarray.flatten(bin_counts.astype(int)))\n",
    "    \n",
    "    return pd.DataFrame({'K': K, 'N(K)': NK})\n",
    "\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "def poisson_distribution_table(k, mu):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    k: array\n",
    "        Macierz 1D z wariantami badanej cechy, dla którym ma zostać wyliczone prawdopodobieństwo.\n",
    "    mu: int\n",
    "        Wartość oczekiwana rozkładu Poissona.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    table: DataFrame\n",
    "        Tablica zawierająca 2 kolumny:\n",
    "        - \"K\", która zawiera warianty badanej cechy,\n",
    "        - \"P(K)\", która zawiera wartości prawdopodobieństw rozkładu Poissona wyliczone dla wartości oczekiwanej mu\n",
    "        oraz poszczególnych wariantów badanej cechy znormalizowane do sumy wartości równej 1.\n",
    "    \"\"\"  \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # calculating poisson pmf\n",
    "    dp = sp.stats.poisson.pmf(k,mu)\n",
    "    dp /= sum(dp)\n",
    "\n",
    "    return pd.DataFrame({'K': k, 'P(K)': dp})\n",
    "\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "def pearsons_chi2_test(tested_distribution, theoretical_distribution, alpha, ddof):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    tested_distribution: DataFrame\n",
    "        Tablica opisująca testowany rozkład i zawierająca 2 kolumny:\n",
    "        - \"K\", która zawiera warianty badanej cechy, wartości muszą być identycznej jak kolumna \"K\" zmiennej lokalnej theoretical_distribution,\n",
    "        - \"N(K)\", która zawiera liczebności poszczególnych wariantów badanej cechy.\n",
    "\n",
    "    theoretical_distribution: DataFrame\n",
    "        Tablica opisująca rozkład teoretyczny i zawierająca 2 kolumny:\n",
    "        - \"K\", która zawiera warianty badanej cechy, wartości muszą być identycznej jak kolumna \"K\" zmiennej lokalnej tested_distribution,\n",
    "        - \"P(K)\", która zawiera prawdopodobieństwa poszczególnych wariantów badanej cechy. Wartości z tej kolumny muszą sumować się do 1.\n",
    "    \n",
    "    alpha: float\n",
    "        Wartość z zakresu [0,1] określająca poziom istotności.\n",
    "    \n",
    "    ddof: int\n",
    "        Liczba nieujemna określająca liczbę nieznanych parametrów rozkładu.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    chi2 = 0\n",
    "    sum = tested_distribution[\"N(K)\"].sum()\n",
    "\n",
    "    # calculating chi^2\n",
    "    for i in range(len(theoretical_distribution['K'])):\n",
    "          chi2 += ((tested_distribution.iloc[i, 1] - sum*theoretical_distribution.iloc[i, 1])**2)/ \\\n",
    "          (sum*theoretical_distribution.iloc[i, 1])\n",
    "\n",
    "    # calculating chi^2_alfa via function from scipy library\n",
    "    chi2_alpha = sp.stats.chi2.ppf(1-alpha, len(theoretical_distribution['K'])-ddof-1)\n",
    "\n",
    "    # pretty printing of the results\n",
    "    print(\"Test chi-kwadrat Pearsona\")\n",
    "    print(\"H0: Testowana zmienna ma przyjęty rozkład teoretyczny\\nH1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\")\n",
    "    print(\"chi2 =\", chi2, \"lambda_alpha =\", chi2_alpha)\n",
    "    \n",
    "    if chi2 >= chi2_alpha:\n",
    "        print(\"chi2 >= chi2_alpha\")\n",
    "        print(\"Odrzucenie H0 na rzecz H1 na poziomie istotności alpha =\",alpha)\n",
    "    else:\n",
    "        print(\"chi2 < chi2_alpha\")\n",
    "        print(\"Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha =\",alpha)\n",
    "        \n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4717de4-5c60-4edd-88a9-6c1a296da5e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c87021b1e1c33db87458c8245bac7972",
     "grade": false,
     "grade_id": "cell-8faafe8175d68f1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### b) Weryfikacja hipotezy o rozkładzie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684018bf-b940-4b7d-b370-6cb84f951028",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "050b275460b26403b19391a8d71f095d",
     "grade": true,
     "grade_id": "cell-10530e4bdc225d2e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chi-kwadrat Pearsona\n",
      "H0: Testowana zmienna ma przyjęty rozkład teoretyczny\n",
      "H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\n",
      "chi2 = 17.77538534909442 lambda_alpha = 22.362032494826934\n",
      "chi2 < chi2_alpha\n",
      "Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha = 0.05\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "area = 0.5**2 # surface area of our subregions (x_lim[1]/bins[0]*y_lim[1]/bins[1])\n",
    "dt=distribution_table(n1)\n",
    "pdt=poisson_distribution_table(dt[\"K\"], 20 * area)\n",
    "#print(pdt)\n",
    "pearsons_chi2_test(dt, pdt, 0.05, 0)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b23413-4913-4792-9232-179b65824458",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8e2a2cbf02e7f2ae96e022496bf73c7",
     "grade": false,
     "grade_id": "cell-6278fccf5c8254be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### c) Weryfikacja hipotezy o rozkładzie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40328148-42ac-443f-a33e-acf562aa69f9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a38294ac11132e0606cc55adc9fb4537",
     "grade": true,
     "grade_id": "cell-6c54b48d31e662da",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chi-kwadrat Pearsona\n",
      "H0: Testowana zmienna ma przyjęty rozkład teoretyczny\n",
      "H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\n",
      "chi2 = 86.27901230036939 lambda_alpha = 22.362032494826934\n",
      "chi2 >= chi2_alpha\n",
      "Odrzucenie H0 na rzecz H1 na poziomie istotności alpha = 0.05\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "dt=distribution_table(n2)\n",
    "pdt=poisson_distribution_table(dt[\"K\"], 20 * area)\n",
    "#print(pdt)\n",
    "pearsons_chi2_test(dt, pdt, 0.05, 0)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb8c0a3-36c4-4eee-a0a3-82f5f93008c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54173c3c63922e471c1eed46a21f9b71",
     "grade": false,
     "grade_id": "cell-46f87024c5253ba3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Zadanie 2: Test Kołmogorowa - Smirnowa (20 pkt)\n",
    "\n",
    "Przygotuj funkcję `kolmogorow_smirnow_test()`, która będzie przeprowadzać test istotności Kołmogorowa-Smirnowa i wyświetlać jego wynik zgodnie z pokazanym poniżej schematem. Następnie wykorzystaj przygotowanią funkcję do sprawdzenia, czy rozkład punktowy zaimportowany z pliku points_3.csv jest jednorodnym rozkładem Poissona. W obliczeniach przyjmij poziom istotności $\\alpha=0.05$.\n",
    "\n",
    "Algorytm postępowania:\n",
    "- Formułujemy hipotezę zerową i hipotezę alternatywną H1: <br/>\n",
    "H0: Testowana zmienna ma przyjęty rozkład teoretyczny <br/>\n",
    "H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\n",
    "- Obliczamy wartość statystyki testowej $\\lambda$: <br/>\n",
    "$D = \\sup_{x}(|F_t - F_0|)$ <br/>\n",
    "$\\lambda = D\\sqrt{n}$ <br/>\n",
    "gdzie: $F_t$ - dystrybuanta testowanego rozkładu,  $F_0$ - dystrybuanta rozkładu teoretycznego, $n$ - liczba punktów.\n",
    "- Z rozkładu Kołomogorowa wyznaczamy obszar krytyczny testu istotności $\\lambda_{\\alpha}$: <br/>\n",
    "$\\lambda_{\\alpha} = \\lambda_{1-\\alpha}$ <br/>\n",
    "gdzie:  $\\alpha$ - poziom istotności.\n",
    "- Podejmujemy decyzję weryfikującą: <br/>\n",
    "$\\lambda >= \\lambda_{\\alpha}$ - Odrzucenie H0 na rzecz H1 na poziomie istotności alpha = X <br/>\n",
    "$\\lambda < \\lambda_{\\alpha}$ - Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha = X\n",
    "\n",
    "Uwaga! Test należy przeprowadzić niezależnie dla współrzędnej X i Y. Decyzja jest podejmowana na podstawie wyników obu testów.\n",
    "\n",
    "\n",
    "Przykładowe wyniki pracy funkcji `kolmogorow_smirnow_test()`: <br/>\n",
    "<br/>\n",
    "`Test Kołmogorowa-Smirnowa dla współrzędnej X` <br/>\n",
    "`H0: Testowana zmienna ma przyjęty rozkład teoretyczny` <br/>\n",
    "`H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego` <br/>\n",
    "`lambda = 2.036  lambda_alpha = 1.255`<br/>\n",
    "`lambda >= lambda_alpha` <br/>\n",
    "`Odrzucenie H0 na rzecz H1 na poziomie istotności alpha = 0.05` <br/>\n",
    "<br/>\n",
    "`Test Kołmogorowa-Smirnowa dla współrzędnej Y` <br/>\n",
    "`H0: Testowana zmienna ma przyjęty rozkład teoretyczny` <br/>\n",
    "`H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego` <br/>\n",
    "`lambda = 1.136  lambda_alpha = 1.748` <br/>\n",
    "`lambda < D_alpha` <br/>\n",
    "`Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha = 0.05`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71dfcb-8675-4dc3-bc86-0cbbb86c9d6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57120b85d632c43b08cf4d21fca7d8d9",
     "grade": false,
     "grade_id": "cell-b572214484a8c02e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### a) Przygotowanie funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13e653bc-c56b-42d8-95a5-3d5ac5b8eeff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f57a4fa3ac67a55876d97fbdfb726b",
     "grade": true,
     "grade_id": "cell-2f066333ab586e29",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kolmogorow_smirnow_test(tested_points, theoretical_points, alpha, ddof):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -------\n",
    "    tested_points: DataFrame\n",
    "        Tablica zawierająca kolumnę ze współrzędnymi punktów testowanego rozkładu opisaną jako \"X\" lub \"Y\".\n",
    "\n",
    "    theoretical_points: DataFrame\n",
    "        Tablica zawierająca kolumnę ze współrzędnymi punktów toeretycznego rozkładu opisaną jako \"X\" lub \"Y\".\n",
    "    \n",
    "    alpha: float\n",
    "        Wartość z zakresu [0,1] określająca poziom istotności.\n",
    "    \n",
    "    ddof: int\n",
    "        Liczba nieujemna określająca liczbę nieznanych parametrów rozkładu.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #counting value of D\n",
    "    D = sp.stats.kstest(tested_points,theoretical_points)\n",
    "    D = D.statistic\n",
    "    \n",
    "    #counting lambdas' values\n",
    "    lam = D*len(tested_points)**0.5\n",
    "    lam_alpha = sp.stats.kstwobign.ppf(1-alpha)\n",
    "    \n",
    "    #printing results\n",
    "    col = tested_points.name\n",
    "    print(\"Test Kołmogorowa-Smirnowa dla współrzędnej\",col)\n",
    "    print(\"H0: Testowana zmienna ma przyjęty rozkład teoretyczny\\nH1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\")\n",
    "    print(\"lambda =\", lam, \"lambda_alpha =\", lam_alpha)\n",
    "    \n",
    "    if lam >= lam_alpha:\n",
    "        print(\"lambda >= lambda_alpha\")\n",
    "        print(\"Odrzucenie H0 na rzecz H1 na poziomie istotności alpha =\",alpha)\n",
    "    else:\n",
    "        print(\"lambda < lambda_alpha\")\n",
    "        print(\"Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha =\",alpha)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853e0f4-8b60-4773-956e-ba988fc22cb1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1cb5d14963e6cd5d55b13fe85196de9",
     "grade": false,
     "grade_id": "cell-3912a59c00ac417b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### b) Weryfikacja hipotezy o rozkładzie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c70431-2637-4377-96d0-a6d7eb27ad7e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c51fd2090383864238854567c520a1af",
     "grade": true,
     "grade_id": "cell-a815b45ab15cc87c",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Kołmogorowa-Smirnowa dla współrzędnej X\n",
      "H0: Testowana zmienna ma przyjęty rozkład teoretyczny\n",
      "H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\n",
      "lambda = 2.155744924824021 lambda_alpha = 1.3580986393225505\n",
      "lambda >= lambda_alpha\n",
      "Odrzucenie H0 na rzecz H1 na poziomie istotności alpha = 0.05\n",
      "\n",
      "\n",
      "Test Kołmogorowa-Smirnowa dla współrzędnej Y\n",
      "H0: Testowana zmienna ma przyjęty rozkład teoretyczny\n",
      "H1: Testowana zmienna nie ma przyjętego rozkładu teoretycznego\n",
      "lambda = 0.5706383624534173 lambda_alpha = 1.3580986393225505\n",
      "lambda < lambda_alpha\n",
      "Wynik testu istotności nie daje podstaw do odrzucenia H0 na rzecz H1 na poziomie istotności alpha = 0.05\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "kolmogorow_smirnow_test(points_3['X'], np.linspace(min(points_3['X']),max(points_3['X']),len(points_3['X'])), 0.05, 0)\n",
    "print(\"\\n\")\n",
    "kolmogorow_smirnow_test(points_3['Y'], np.linspace(min(points_3['Y']),max(points_3['Y']),len(points_3['Y'])), 0.05, 0)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
